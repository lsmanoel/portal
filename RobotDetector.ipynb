{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RobotDetector.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lsmanoel/portal/blob/master/RobotDetector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0MqVRHVFgcU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 764
        },
        "outputId": "207cec08-f427-44f3-bebf-bf013994a1e0"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# To install the packages in colaboratory workspace:\n",
        "!apt update\n",
        "!apt install -y cmake\n",
        "!apt install python3-tk\n",
        "!pip install dlib\n",
        "\n",
        "import cv2\n",
        "import dlib"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (91.189.88.24)] [1 InRelease 0 B/88.7 kB 0\u001b[0m\u001b[33m\r0% [Waiting for headers] [Connected to cloud.r-project.org (13.33.57.50)] [Wait\u001b[0m\r                                                                               \rIgn:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [Connected to cloud.r-project.org (13.33.57.50)] [Wait\u001b[0m\u001b[33m\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Connected to cloud.r-proje\u001b[0m\r                                                                               \rHit:3 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "\u001b[33m\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Connected to cloud.r-proje\u001b[0m\r                                                                               \rHit:4 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\u001b[33m\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Connected to cloud.r-proje\u001b[0m\r                                                                               \rIgn:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\u001b[33m\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Waiting for headers] [Conn\u001b[0m\r                                                                               \rHit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Get:7 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease [3,626 B]\n",
            "Get:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release [564 B]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:10 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release.gpg [801 B]\n",
            "Get:11 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease [15.4 kB]\n",
            "Get:12 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [720 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [570 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:16 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ Packages [58.4 kB]\n",
            "Get:17 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Packages [10.8 kB]\n",
            "Get:18 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main Sources [1,648 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [879 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [1,232 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 Packages [3,927 B]\n",
            "Get:22 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main amd64 Packages [791 kB]\n",
            "Fetched 6,185 kB in 3s (1,942 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "41 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "cmake is already the newest version (3.10.2-1ubuntu2).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 41 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python3-tk is already the newest version (3.6.8-1~18.04).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 41 not upgraded.\n",
            "Requirement already satisfied: dlib in /usr/local/lib/python3.6/dist-packages (19.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKZumzsMESJQ",
        "colab_type": "text"
      },
      "source": [
        "The method **train_shape_predictor()** has several parameters of options. All parameters come with reasonable default values. \n",
        "\n",
        "The Parametes: [class dlib.shape_predictor_training_options](http://dlib.net/python/index.html#dlib.shape_predictor_training_options)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLlMnno7F79-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "options = dlib.simple_object_detector_training_options()\n",
        "\n",
        "# #-------------------------------------------------------------------------------\n",
        "# # During training stage: This option flip the input image. \n",
        "# # This helps it get the most value out of the training data.\n",
        "# options.add_left_right_image_flips = False\n",
        "\n",
        "# #-------------------------------------------------------------------------------\n",
        "# # The trainer is a kind of support vector machine and therefore has the usual\n",
        "# # SVM C parameter.  In general, a bigger C encourages it to fit the training\n",
        "# # data better but might lead to overfitting.  You must find the best C value\n",
        "# # empirically by checking how well the trained detector works on a test set of\n",
        "# # images you haven't trained on.  Don't just leave the value set at 5.  Try a\n",
        "# # few different C values and see what works best for your data.\n",
        "# options.C = 5\n",
        "\n",
        "# #-------------------------------------------------------------------------------\n",
        "# # Set how many CPU cores your computer has for the fastest training.\n",
        "# options.num_threads = 1\n",
        "\n",
        "# #-------------------------------------------------------------------------------\n",
        "# # Verbose Mode\n",
        "# options.be_verbose = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bD2jxzeYGIcq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_1_folder = \"gdrive/My Drive/Colab Notebooks/Dlib/ObjectDetector/image_datasets/qrcodes_partitioned/qrcodes_dataset_1/\"\n",
        "dataset_2_folder = \"gdrive/My Drive/Colab Notebooks/Dlib/ObjectDetector/image_datasets/qrcodes_partitioned/qrcodes_dataset_2/\"\n",
        "dataset_3_folder = \"gdrive/My Drive/Colab Notebooks/Dlib/ObjectDetector/image_datasets/qrcodes_partitioned/qrcodes_dataset_3/\"\n",
        "dataset_4_folder = \"gdrive/My Drive/Colab Notebooks/Dlib/ObjectDetector/image_datasets/qrcodes_partitioned/qrcodes_dataset_4/\"\n",
        "dataset_5_folder = \"gdrive/My Drive/Colab Notebooks/Dlib/ObjectDetector/image_datasets/qrcodes_partitioned/qrcodes_dataset_5/\"\n",
        "training_1_xml_path = os.path.join(dataset_1_folder, \"qrcode_dataset_1_ROI.xml\")\n",
        "training_2_xml_path = os.path.join(dataset_2_folder, \"qrcode_dataset_2_ROI.xml\")\n",
        "training_3_xml_path = os.path.join(dataset_3_folder, \"qrcode_dataset_3_ROI.xml\")\n",
        "training_4_xml_path = os.path.join(dataset_4_folder, \"qrcode_dataset_4_ROI.xml\")\n",
        "training_5_xml_path = os.path.join(dataset_5_folder, \"qrcode_dataset_5_ROI.xml\")\n",
        "\n",
        "dataset_test_folder = \"gdrive/My Drive/Colab Notebooks/Dlib/ObjectDetector/image_datasets/qrcodes_testset/\"\n",
        "testing_xml_path = os.path.join(dataset_test_folder, \"test_qrcode_ROI.xml\")\n",
        "\n",
        "svm_1_path = os.path.join(dataset_1_folder, \"detector_1.svm\")\n",
        "svm_2_path = os.path.join(dataset_2_folder, \"detector_2.svm\")\n",
        "svm_3_path = os.path.join(dataset_3_folder, \"detector_3.svm\")\n",
        "svm_4_path = os.path.join(dataset_4_folder, \"detector_4.svm\")\n",
        "svm_5_path = os.path.join(dataset_5_folder, \"detector_5.svm\")\n",
        "\n",
        "landmarks_1_path = os.path.join(dataset_1_folder, \"landmarks_1.dat\")\n",
        "landmarks_2_path = os.path.join(dataset_2_folder, \"landmarks_2.dat\")\n",
        "landmarks_3_path = os.path.join(dataset_3_folder, \"landmarks_3.dat\")\n",
        "landmarks_4_path = os.path.join(dataset_4_folder, \"landmarks_4.dat\")\n",
        "landmarks_5_path = os.path.join(dataset_5_folder, \"landmarks_5.dat\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}